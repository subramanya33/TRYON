{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoseNet model found at c:\\Users\\subbu\\OneDrive\\Desktop\\FINALYEAR\\media\\posenet_mobilenet_v1_100_257x257_multi_kpt_stripped.tflite\n",
      "Person image loaded successfully.\n",
      "Clothing image loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Set the base directory (change this to your project root if needed)\n",
    "base_dir = r\"c:\\Users\\subbu\\OneDrive\\Desktop\\FINALYEAR\\media\"\n",
    "\n",
    "# Ensure proper model path and file loading\n",
    "model_path = os.path.join(base_dir, \"posenet_mobilenet_v1_100_257x257_multi_kpt_stripped.tflite\")\n",
    "\n",
    "# Check if the model exists\n",
    "if not os.path.exists(model_path):\n",
    "    print(f\"PoseNet model could not be loaded: Could not open '{model_path}'\")\n",
    "else:\n",
    "    print(f\"PoseNet model found at {model_path}\")\n",
    "    # Load the PoseNet model\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "# Ensure correct paths for person and clothing images\n",
    "person_image_path = os.path.join(base_dir, \"testproj.jpg\")\n",
    "dress_image_path = os.path.join(base_dir,  \"dresss.jpg\")\n",
    "\n",
    "# Check if person image exists\n",
    "if not os.path.exists(person_image_path):\n",
    "    print(f\"Failed to load person image: {person_image_path}\")\n",
    "    person_image = None\n",
    "else:\n",
    "    person_image = cv2.imread(person_image_path)\n",
    "    if person_image is not None:\n",
    "        print(\"Person image loaded successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to read the person image from: {person_image_path}\")\n",
    "\n",
    "# Check if clothing image exists\n",
    "if not os.path.exists(dress_image_path):\n",
    "    print(f\"Failed to load clothing image: {dress_image_path}\")\n",
    "    clothing_image = None\n",
    "else:\n",
    "    clothing_image = cv2.imread(dress_image_path)\n",
    "    if clothing_image is not None:\n",
    "        print(\"Clothing image loaded successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to read the clothing image from: {dress_image_path}\")\n",
    "\n",
    "# Proceed only if both images and the model are loaded\n",
    "if person_image is not None and clothing_image is not None:\n",
    "\n",
    "    # Example: Dummy keypoints for testing (replace with actual PoseNet inference output)\n",
    "    keypoints = {\n",
    "        0: {\n",
    "            5: [100, 150],  # Left shoulder\n",
    "            6: [200, 150],  # Right shoulder\n",
    "            11: [100, 300], # Left hip\n",
    "            12: [200, 300]  # Right hip\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Extract relevant keypoints\n",
    "    try:\n",
    "        left_shoulder = keypoints[0][5]\n",
    "        right_shoulder = keypoints[0][6]\n",
    "        left_hip = keypoints[0][11]\n",
    "        right_hip = keypoints[0][12]\n",
    "\n",
    "        # Define source points in the clothing image (you can adjust these points)\n",
    "        source_points = np.float32([[0, 0], [clothing_image.shape[1], 0], [0, clothing_image.shape[0]]])\n",
    "        \n",
    "        # Define destination points on the person's body (using keypoints)\n",
    "        destination_points = np.float32([left_shoulder, right_shoulder, left_hip])\n",
    "\n",
    "        # Compute the transformation matrix for warping the clothing image onto the person image\n",
    "        M = cv2.getAffineTransform(source_points, destination_points)\n",
    "\n",
    "        # Apply affine transformation to warp the clothing image\n",
    "        warped_clothing = cv2.warpAffine(clothing_image, M, (person_image.shape[1], person_image.shape[0]))\n",
    "\n",
    "        # Create a mask for the warped clothing (you can refine this for blending)\n",
    "        clothing_mask = warped_clothing[:, :, 0] > 0  # Non-black pixels in clothing\n",
    "\n",
    "        # Overlay the clothing on the person image\n",
    "        result_image = person_image.copy()\n",
    "        result_image[clothing_mask] = warped_clothing[clothing_mask]\n",
    "\n",
    "        # Show the final image\n",
    "        cv2.imshow('Virtual Try-On Result', result_image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    except IndexError as e:\n",
    "        print(f\"Failed to get keypoints: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"Ensure both images are properly loaded before proceeding.\")#loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 11 is out of bounds for axis 0 with size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m left_shoulder \u001b[38;5;241m=\u001b[39m keypoints[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m5\u001b[39m]\n\u001b[0;32m     39\u001b[0m right_shoulder \u001b[38;5;241m=\u001b[39m keypoints[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m6\u001b[39m]\n\u001b[1;32m---> 40\u001b[0m left_hip \u001b[38;5;241m=\u001b[39m \u001b[43mkeypoints\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     41\u001b[0m right_hip \u001b[38;5;241m=\u001b[39m keypoints[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m12\u001b[39m]\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Resize clothing to match the shoulder width\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 11 is out of bounds for axis 0 with size 9"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.interpolate import Rbf\n",
    "\n",
    "# Load the PoseNet model\n",
    "model_path = r\"c:\\Users\\subbu\\OneDrive\\Desktop\\FINALYEAR\\media\\posenet_mobilenet_v1_100_257x257_multi_kpt_stripped.tflite\"\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Function to detect keypoints\n",
    "def detect_keypoints(interpreter, image):\n",
    "    # Prepare the input image for PoseNet\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    input_shape = input_details[0]['shape']\n",
    "\n",
    "    # Resize and normalize the input image\n",
    "    image_resized = cv2.resize(image, (input_shape[2], input_shape[1]))\n",
    "    input_data = np.expand_dims(image_resized.astype(np.float32), axis=0)\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # Extract keypoints\n",
    "    keypoints = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "    return keypoints\n",
    "\n",
    "# Load images\n",
    "person_image_path = r\"c:\\Users\\subbu\\OneDrive\\Desktop\\FINALYEAR\\media\\testproj.jpg\"\n",
    "dress_image_path = r\"c:\\Users\\subbu\\OneDrive\\Desktop\\FINALYEAR\\media\\dresss.jpg\"\n",
    "person_image = cv2.imread(person_image_path)\n",
    "clothing_image = cv2.imread(dress_image_path)\n",
    "\n",
    "# Detect keypoints in the person image\n",
    "keypoints = detect_keypoints(interpreter, person_image)\n",
    "\n",
    "# Use detected keypoints for left/right shoulders and hips\n",
    "left_shoulder = keypoints[0][5]\n",
    "right_shoulder = keypoints[0][6]\n",
    "left_hip = keypoints[0][11]\n",
    "right_hip = keypoints[0][12]\n",
    "\n",
    "# Resize clothing to match the shoulder width\n",
    "shoulder_width = int(np.linalg.norm(np.array(left_shoulder) - np.array(right_shoulder)))\n",
    "aspect_ratio = clothing_image.shape[1] / clothing_image.shape[0]\n",
    "new_height = int(shoulder_width / aspect_ratio)\n",
    "clothing_image = cv2.resize(clothing_image, (shoulder_width, new_height))\n",
    "\n",
    "# Define clothing source and target points for TPS\n",
    "source_points = np.float32([\n",
    "    [0, 0],\n",
    "    [clothing_image.shape[1], 0],\n",
    "    [0, clothing_image.shape[0]],\n",
    "    [clothing_image.shape[1], clothing_image.shape[0]]\n",
    "])\n",
    "destination_points = np.float32([left_shoulder, right_shoulder, left_hip, right_hip])\n",
    "\n",
    "# Thin Plate Spline transformation using RBF\n",
    "def apply_tps_transform(source, destination, image_shape):\n",
    "    x = np.array([p[0] for p in destination], dtype=np.float32)\n",
    "    y = np.array([p[1] for p in destination], dtype=np.float32)\n",
    "    z_x = np.array([p[0] for p in source], dtype=np.float32)\n",
    "    z_y = np.array([p[1] for p in source], dtype=np.float32)\n",
    "\n",
    "    # RBF Interpolation\n",
    "    rbf_x = Rbf(x, y, z_x, function='thin_plate')\n",
    "    rbf_y = Rbf(x, y, z_y, function='thin_plate')\n",
    "\n",
    "    grid_x, grid_y = np.meshgrid(np.arange(image_shape[1]), np.arange(image_shape[0]))\n",
    "    map_x = rbf_x(grid_x, grid_y).astype(np.float32)\n",
    "    map_y = rbf_y(grid_x, grid_y).astype(np.float32)\n",
    "\n",
    "    return map_x, map_y\n",
    "\n",
    "# Generate transformation mapping using TPS\n",
    "map_x, map_y = apply_tps_transform(source_points, destination_points, person_image.shape)\n",
    "\n",
    "# Apply warp using remap for a flexible transformation\n",
    "warped_clothing = cv2.remap(clothing_image, map_x, map_y, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0))\n",
    "\n",
    "# Create a binary mask from the warped clothing\n",
    "_, clothing_mask = cv2.threshold(cv2.cvtColor(warped_clothing, cv2.COLOR_BGR2GRAY), 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Refine edges by blurring\n",
    "clothing_mask = cv2.GaussianBlur(clothing_mask, (5, 5), 0)\n",
    "\n",
    "# Invert mask for person background\n",
    "inverse_mask = cv2.bitwise_not(clothing_mask)\n",
    "\n",
    "# Mask the person image background\n",
    "person_bg = cv2.bitwise_and(person_image, person_image, mask=inverse_mask)\n",
    "\n",
    "# Isolate the clothing region from the warped clothing image\n",
    "clothing_fg = cv2.bitwise_and(warped_clothing, warped_clothing, mask=clothing_mask)\n",
    "\n",
    "# Combine images\n",
    "result_image = cv2.add(person_bg, clothing_fg)\n",
    "\n",
    "# Display the final result\n",
    "cv2.imshow(\"Virtual Try-On Result\", result_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
